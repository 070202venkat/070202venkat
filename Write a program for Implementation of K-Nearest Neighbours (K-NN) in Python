import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn import datasets from sklearn.metrics import accuracy_score

Load the Iris dataset

iris = datasets.load_iris() X = iris.data y = iris.target

Split the dataset into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Standardize features for better performance

scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test)

Train the K-NN classifier

k = 5  # Number of neighbors knn = KNeighborsClassifier(n_neighbors=k) knn.fit(X_train, y_train)

Predict the test set results

y_pred = knn.predict(X_test)

Evaluate the model

accuracy = accuracy_score(y_test, y_pred) print(f'K-NN Model Accuracy: {accuracy * 100:.2f}%')

Visualizing decision boundary (optional, works for 2D datasets)

def plot_decision_boundary(X, y, model, title): h = .02  # step size in the mesh x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, alpha=0.3)

scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', marker='o')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title(title)
plt.show()

Reduce dimensions for visualization (if needed)

if X.shape[1] > 2: from sklearn.decomposition import PCA pca = PCA(n_components=2) X_train_2D = pca.fit_transform(X_train) X_test_2D = pca.transform(X_test) knn.fit(X_train_2D, y_train) plot_decision_boundary(X_test_2D, y_test, knn, 'K-NN Decision Boundary (2D Projection)')


import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.naive_bayes import GaussianNB from sklearn.svm import SVC from sklearn.neighbors import KNeighborsClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score, classification_report, confusion_matrix from sklearn.datasets import load_iris

Load dataset

iris = load_iris() df = pd.DataFrame(data=iris.data, columns=iris.feature_names) df['species'] = iris.target

Display first few rows

display(df.head())

Splitting features and target

X = df.drop("species", axis=1) y = df["species"]

Train-test split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Feature Scaling

scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test)

Define classifiers

classifiers = { "Naive Bayes": GaussianNB(), "Support Vector Machine": SVC(kernel='linear', random_state=42), "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=3), "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42) }

Train and evaluate classifiers

results = {} for name, model in classifiers.items(): model.fit(X_train, y_train) y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred) results[name] = accuracy print(f"{name} Accuracy: {accuracy:.4f}") print("Classification Report:") print(classification_report(y_test, y_pred)) print("Confusion Matrix:") print(confusion_matrix(y_test, y_pred)) print("\n" + "-"*50 + "\n")

Visualization

plt.figure(figsize=(8,6)) plt.bar(results.keys(), results.values(), color=['blue', 'green', 'red', 'purple']) plt.xlabel("Classification Algorithm") plt.ylabel("Accuracy Score") plt.title("Comparison of Classification Algorithms") plt.ylim(0, 1) plt.show()

